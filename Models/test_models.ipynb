{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68b5ea8-1666-4c81-b375-ba0fb2af9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f84460-7c0e-4c81-9038-0c17c852806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7924c51-8f29-41f6-87e2-3a49d1e6089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regular import RegularTransformer, RegularFeedForward\n",
    "from projected import ProjectedTransformer, ProjectedFeedForward\n",
    "from exponential import ExponentialTransformer, ExponentialFeedForward\n",
    "from train_constrained import train_model\n",
    "import projections\n",
    "import exponentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175f2abd-ba11-48a8-830a-d6c8f77fc2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_so3(X: torch.Tensor, atol: float = 1e-3):\n",
    "    assert X.dim() == 2 and X.shape[1] == 9\n",
    "    R = X.view(-1, 3, 3)\n",
    "\n",
    "    I = torch.eye(3, device=R.device, dtype=R.dtype).expand(R.shape[0], 3, 3)\n",
    "    ortho_err = torch.linalg.norm(R.transpose(-1, -2) @ R - I, dim=(-2, -1))  # (B,)\n",
    "    det_err = torch.abs(torch.linalg.det(R) - 1.0)                            # (B,)\n",
    "\n",
    "    ok = (ortho_err <= atol) & (det_err <= atol)\n",
    "    return {\"ok\": ok, \"ortho_err\": ortho_err, \"det_err\": det_err}\n",
    "\n",
    "def check_so3_flat(R9: torch.Tensor, tol: float = 1e-4):\n",
    "    \"\"\"\n",
    "    R9: [B, 9] or [B, S, 9]\n",
    "    Returns: (ok_mask, max_orth_err, max_det_err)\n",
    "    \"\"\"\n",
    "    orig = R9.shape\n",
    "    if R9.dim() == 3:\n",
    "        B, S, _ = orig\n",
    "        R = R9.reshape(B*S, 3, 3)\n",
    "    else:\n",
    "        B = orig[0]\n",
    "        R = R9.reshape(B, 3, 3)\n",
    "\n",
    "    I = torch.eye(3, device=R.device, dtype=R.dtype).expand(R.shape[0], 3, 3)\n",
    "    orth_err = torch.linalg.norm(R.transpose(-1, -2) @ R - I, dim=(-2, -1))\n",
    "    det_err  = torch.abs(torch.linalg.det(R) - 1.0)\n",
    "\n",
    "    ok = (orth_err <= tol) & (det_err <= tol)\n",
    "    if R9.dim() == 3:\n",
    "        ok = ok.reshape(B, S)\n",
    "\n",
    "    return ok, orth_err.max().item(), det_err.max().item()\n",
    "\n",
    "\n",
    "def check_se3_flat(G16: torch.Tensor, tol_R: float = 1e-4, tol_last: float = 1e-6):\n",
    "    \"\"\"\n",
    "    G16: [B, 16] (row-major flatten of 4x4).\n",
    "    Checks:\n",
    "      - top-left 3x3 is in SO(3) (via check_so3_flat)\n",
    "      - last row equals [0,0,0,1]\n",
    "    Returns: dict with masks + max errors.\n",
    "    \"\"\"\n",
    "    B = G16.shape[0]\n",
    "    G = G16.reshape(B, 4, 4)\n",
    "\n",
    "    R = G[:, :3, :3].reshape(B, 9)          # [B,9]\n",
    "    ok_R, max_orth, max_det = check_so3_flat(R, tol=tol_R)\n",
    "\n",
    "    last = G[:, 3, :]                        # [B,4]\n",
    "    target = torch.tensor([0., 0., 0., 1.], device=G.device, dtype=G.dtype).expand_as(last)\n",
    "    last_err = torch.max(torch.abs(last - target), dim=-1).values  # [B]\n",
    "    ok_last = last_err <= tol_last\n",
    "\n",
    "    ok_all = ok_R & ok_last\n",
    "\n",
    "    return dict(\n",
    "        ok=ok_all,\n",
    "        ok_R=ok_R,\n",
    "        ok_last_row=ok_last,\n",
    "        max_orth_err=max_orth,\n",
    "        max_det_err=max_det,\n",
    "        max_last_row_err=last_err.max().item(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b7df46-9db9-421a-8ad1-fbf403cb623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (4000, 9)\n",
      "Y_train (4000, 9)\n",
      "X_val (800, 9)\n",
      "Y_val (800, 9)\n",
      "X_test (1200, 9)\n",
      "Y_test (1200, 9)\n"
     ]
    }
   ],
   "source": [
    "loaded = torch.load(\"./../Data/so3_dataset.pt\", map_location=\"cpu\", weights_only = False)\n",
    "\n",
    "for k, v in loaded.items():\n",
    "    try:\n",
    "        print(k, v.shape)\n",
    "    except AttributeError:\n",
    "        print(k, type(v))\n",
    "\n",
    "X_train = torch.tensor(loaded['X_train'], dtype = torch.float32)\n",
    "Y_train = torch.tensor(loaded['Y_train'], dtype = torch.float32)\n",
    "\n",
    "for name in [\"X_train\",\"Y_train\",\"X_val\",\"Y_val\",\"X_test\",\"Y_test\"]:\n",
    "    assert torch.isfinite(torch.tensor(loaded[name])).all(), f\"Found NaN/Inf in {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487e0442-a5e2-44ee-9c4c-f38424137725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExponentialFeedForward(9,3,3, exp_func = exponentials.so3, use_internal_exponential = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3ab1eb9d-2513-4730-8650-1d15b926dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9945) 1.4141149520874023 0.9881886839866638 0.0\n"
     ]
    }
   ],
   "source": [
    "out = check_se3_flat(Y_train, tol_R=1e-4, tol_last=1e-6)\n",
    "print(out[\"ok\"].float().mean(), out[\"max_orth_err\"], out[\"max_det_err\"], out[\"max_last_row_err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "adea6202-298f-48b7-a9eb-e3945f7f31f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(2.1100e-07) tensor(2.3842e-07)\n"
     ]
    }
   ],
   "source": [
    "out = check_so3(X_train, atol=1e-5)\n",
    "print(out[\"ok\"].float().mean(), out[\"ortho_err\"].max(), out[\"det_err\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "439fc2ed-7e59-44ce-be0b-c607eb874f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "348f4673-d06e-4ab1-b98c-378a0c72c1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.square().sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa8f59-0757-4a8e-9f0a-15de327bb40a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e31721f8-7da8-42aa-83dc-5c7b8efa286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se3(X_train,0) ok% = 0.9944999814033508 1.4141782522201538 0.99268639087677 0.0\n"
     ]
    }
   ],
   "source": [
    "B = X_train.shape[0]\n",
    "a = torch.randn(B, 6, device=X_train.device, dtype=X_train.dtype)  # trivial tangent\n",
    "dt = torch.tensor(1.0, device=X_train.device, dtype=X_train.dtype)\n",
    "X_step = exponentials.se3(X_step, a, dt)\n",
    "out_step = check_se3_flat(X_step, tol_R=1e-4, tol_last=1e-6)\n",
    "print(\"se3(X_train,0) ok% =\", out_step[\"ok\"].float().mean().item(),\n",
    "      out_step[\"max_orth_err\"], out_step[\"max_det_err\"], out_step[\"max_last_row_err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb838dff-495c-4395-8012-c13fbdad39ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c6f409-6be5-47f4-b960-a087f8cc3a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a9282-01e3-4b75-8783-6380b54b79bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ffeeea48-0e6a-4457-866f-4897d9aca226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9942) 1.4145879745483398 0.9926833510398865 0.0\n"
     ]
    }
   ],
   "source": [
    "out = check_se3_flat(Y_pred, tol_R=1e-2, tol_last=1e-6)\n",
    "print(out[\"ok\"].float().mean(), out[\"max_orth_err\"], out[\"max_det_err\"], out[\"max_last_row_err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a82766d-bdbb-4fe8-b98b-2bd2a3112b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(1.6745e-06, grad_fn=<MaxBackward1>) tensor(1.4305e-06, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "out = check_so3(Y_pred, atol=1e-5)\n",
    "print(out[\"ok\"].float().mean(), out[\"ortho_err\"].max(), out[\"det_err\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d283e960-b39e-4d91-895b-dca5dcc3802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isfinite(Y_pred).all(), f\"Found NaN/Inf in {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d7ddba8b-daca-4269-8e6b-cb49205587f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 3])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bf7e7e-ab66-4a23-9ee7-7f633168926b",
   "metadata": {},
   "source": [
    "# Overfit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1daeb743-a427-409f-8835-5907bd4c26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46470596-9f50-4113-a7cf-89d50ff77f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors\n",
    "X_train = torch.tensor(loaded[\"X_train\"], dtype=torch.float32)\n",
    "Y_train = torch.tensor(loaded[\"Y_train\"], dtype=torch.float32)\n",
    "X_val   = torch.tensor(loaded[\"X_val\"],   dtype=torch.float32)\n",
    "Y_val   = torch.tensor(loaded[\"Y_val\"],   dtype=torch.float32)\n",
    "\n",
    "# datasets\n",
    "train_ds = TensorDataset(X_train[:16,:], Y_train[:16,:])\n",
    "val_ds   = TensorDataset(X_val, Y_val)\n",
    "\n",
    "# loaders\n",
    "batch_size = 256  # change if you want\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d6988-eab2-47b7-aae8-93706c60b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensors\n",
    "X_train = torch.tensor(loaded[\"X_train\"], dtype=torch.float32)\n",
    "Y_train = torch.tensor(loaded[\"Y_train\"], dtype=torch.float32)\n",
    "X_val   = torch.tensor(loaded[\"X_val\"],   dtype=torch.float32)\n",
    "Y_val   = torch.tensor(loaded[\"Y_val\"],   dtype=torch.float32)\n",
    "\n",
    "# compute tau from TRAIN translations (no leakage)\n",
    "G = X_train.view(-1, 4, 4)\n",
    "t = G[:, :3, 3]\n",
    "tau = t.std()   # scalar tensor\n",
    "\n",
    "# normalize translation column (rows 0..2, col 3) in ALL splits\n",
    "def normalize_se3_translation(X16: torch.Tensor, tau: torch.Tensor) -> torch.Tensor:\n",
    "    G = X16.view(-1, 4, 4).clone()\n",
    "    G[:, :3, 3] = G[:, :3, 3] / tau\n",
    "    return G.view(-1, 16)\n",
    "\n",
    "X_train_n = normalize_se3_translation(X_train, tau)\n",
    "Y_train_n = normalize_se3_translation(Y_train, tau)\n",
    "X_val_n   = normalize_se3_translation(X_val,   tau)\n",
    "Y_val_n   = normalize_se3_translation(Y_val,   tau)\n",
    "\n",
    "# datasets (use normalized tensors)\n",
    "train_ds = TensorDataset(X_train_n[:16, :], Y_train_n[:16, :])\n",
    "val_ds   = TensorDataset(X_val_n, Y_val_n)\n",
    "\n",
    "# loaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cef2392a-f757-4568-8649-30ecbdfef78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ExponentialFeedForward(16,6,3, exp_func = exponentials.se3, dropout = 0.0, dt = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc3bb00a-96fa-4100-9ced-5bda24d37c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train 5.511e-01 | val 4.384e-01 | lr 1.0e-03\n",
      "epoch   20 | train 3.941e-01 | val 4.233e-01 | lr 1.0e-03\n",
      "epoch   40 | train 3.627e-01 | val 4.220e-01 | lr 1.0e-03\n",
      "epoch   60 | train 3.400e-01 | val 4.095e-01 | lr 1.0e-03\n",
      "epoch   80 | train 3.205e-01 | val 4.044e-01 | lr 1.0e-03\n",
      "epoch  100 | train 3.033e-01 | val 4.022e-01 | lr 1.0e-03\n",
      "epoch  120 | train 2.880e-01 | val 4.031e-01 | lr 1.0e-03\n",
      "epoch  140 | train 2.736e-01 | val 4.086e-01 | lr 1.0e-03\n",
      "epoch  160 | train 2.578e-01 | val 4.175e-01 | lr 1.0e-03\n",
      "epoch  180 | train 2.400e-01 | val 4.284e-01 | lr 1.0e-03\n",
      "epoch  200 | train 2.202e-01 | val 4.425e-01 | lr 1.0e-03\n",
      "epoch  220 | train 2.009e-01 | val 4.556e-01 | lr 1.0e-03\n",
      "epoch  240 | train 1.838e-01 | val 4.727e-01 | lr 1.0e-03\n",
      "epoch  260 | train 1.666e-01 | val 4.935e-01 | lr 1.0e-03\n",
      "epoch  280 | train 1.493e-01 | val 5.084e-01 | lr 1.0e-03\n",
      "epoch  300 | train 1.324e-01 | val 5.210e-01 | lr 1.0e-03\n",
      "epoch  320 | train 1.152e-01 | val 5.355e-01 | lr 1.0e-03\n",
      "epoch  340 | train 1.006e-01 | val 5.529e-01 | lr 1.0e-03\n",
      "epoch  360 | train 8.888e-02 | val 5.706e-01 | lr 1.0e-03\n",
      "epoch  380 | train 7.950e-02 | val 5.840e-01 | lr 1.0e-03\n",
      "epoch  400 | train 7.179e-02 | val 5.957e-01 | lr 8.0e-04\n",
      "epoch  420 | train 6.642e-02 | val 6.055e-01 | lr 8.0e-04\n",
      "epoch  440 | train 6.151e-02 | val 6.158e-01 | lr 8.0e-04\n",
      "epoch  460 | train 5.690e-02 | val 6.245e-01 | lr 8.0e-04\n",
      "epoch  480 | train 5.243e-02 | val 6.305e-01 | lr 8.0e-04\n",
      "epoch  500 | train 4.791e-02 | val 6.345e-01 | lr 8.0e-04\n",
      "epoch  520 | train 4.327e-02 | val 6.455e-01 | lr 8.0e-04\n",
      "epoch  540 | train 3.911e-02 | val 6.582e-01 | lr 8.0e-04\n",
      "epoch  560 | train 3.508e-02 | val 6.693e-01 | lr 8.0e-04\n",
      "epoch  580 | train 3.131e-02 | val 6.747e-01 | lr 8.0e-04\n",
      "epoch  600 | train 2.763e-02 | val 6.683e-01 | lr 8.0e-04\n",
      "epoch  620 | train 2.421e-02 | val 6.590e-01 | lr 8.0e-04\n",
      "epoch  640 | train 2.100e-02 | val 6.600e-01 | lr 8.0e-04\n",
      "epoch  660 | train 1.801e-02 | val 6.731e-01 | lr 8.0e-04\n",
      "epoch  680 | train 1.512e-02 | val 6.928e-01 | lr 8.0e-04\n",
      "epoch  700 | train 1.258e-02 | val 7.178e-01 | lr 6.4e-04\n",
      "epoch  720 | train 1.078e-02 | val 7.284e-01 | lr 6.4e-04\n",
      "epoch  740 | train 9.286e-03 | val 7.342e-01 | lr 6.4e-04\n",
      "epoch  760 | train 8.049e-03 | val 7.363e-01 | lr 6.4e-04\n",
      "epoch  780 | train 7.042e-03 | val 7.386e-01 | lr 6.4e-04\n",
      "epoch  800 | train 6.138e-03 | val 7.397e-01 | lr 6.4e-04\n",
      "epoch  820 | train 5.430e-03 | val 7.412e-01 | lr 6.4e-04\n",
      "epoch  840 | train 4.842e-03 | val 7.434e-01 | lr 6.4e-04\n",
      "epoch  860 | train 4.332e-03 | val 7.454e-01 | lr 6.4e-04\n",
      "epoch  880 | train 3.887e-03 | val 7.478e-01 | lr 6.4e-04\n",
      "epoch  900 | train 3.502e-03 | val 7.502e-01 | lr 6.4e-04\n",
      "epoch  920 | train 3.165e-03 | val 7.525e-01 | lr 6.4e-04\n",
      "epoch  940 | train 2.868e-03 | val 7.544e-01 | lr 6.4e-04\n",
      "epoch  960 | train 2.605e-03 | val 7.564e-01 | lr 6.4e-04\n",
      "epoch  980 | train 2.373e-03 | val 7.583e-01 | lr 6.4e-04\n",
      "epoch 1000 | train 2.165e-03 | val 7.608e-01 | lr 6.4e-04\n"
     ]
    }
   ],
   "source": [
    "model, logs = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr=1e-3,\n",
    "    num_epochs=1000,\n",
    "    device='cuda',\n",
    "    weight_decay=0,\n",
    "    early_stop=0,      # disable early stopping\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb21063-f72c-4075-bd2e-4512c52bf151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbc58661-2dce-4294-b83f-b561bcb3daa0",
   "metadata": {},
   "source": [
    "# Flow Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "933cfb16-f56f-4a4c-8993-00351adb448b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': '/tmp/sonthal/fm_cache/sphere_dataset.pt',\n",
       " 'train_shape': (4000, 3),\n",
       " 'val_shape': (800, 3),\n",
       " 'hparams': {'dataset': '/tmp/sonthal/fm_cache/sphere_dataset.pt',\n",
       "  'outdir': 'outputs/sphere_dataset/alpha1.0/lr1e-3_wd1e-4',\n",
       "  'hidden_dim': 256,\n",
       "  'num_layers': 8,\n",
       "  'lr': 0.001,\n",
       "  'weight_decay': 0.0001,\n",
       "  'num_epochs': 2000,\n",
       "  'batch_size': 256,\n",
       "  'early_stop': 1000,\n",
       "  'seed': 0,\n",
       "  'device': 'cuda',\n",
       "  'scheduler_patience': 100,\n",
       "  'scheduler_factor': 0.5,\n",
       "  'T': 'auto',\n",
       "  'alpha': 1.0,\n",
       "  'num_timesteps': 30,\n",
       "  'velocity_scale': 0.5,\n",
       "  'velocity_cov_scale': 1.0,\n",
       "  'T_used': 2.0,\n",
       "  'r_median': 1.0},\n",
       " 'best_val_loss': 0.05418527197647602,\n",
       " 'best_epoch': 6,\n",
       " 'epochs_ran': 1007}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_proj_dict = torch.load(\"./outputs/sphere_dataset/alpha1.0/lr1e-3_wd1e-4/model.pt\")\n",
    "torch.load(\"./outputs/sphere_dataset/alpha1.0/lr1e-3_wd1e-4/meta.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5669688-a0ce-4686-b8ff-594d4880a8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['net.0.weight', 'net.0.bias', 'net.1.weight', 'net.1.bias', 'net.4.weight', 'net.4.bias', 'net.5.weight', 'net.5.bias', 'net.8.weight', 'net.8.bias', 'net.9.weight', 'net.9.bias', 'net.12.weight', 'net.12.bias', 'net.13.weight', 'net.13.bias', 'net.16.weight', 'net.16.bias', 'net.17.weight', 'net.17.bias', 'net.20.weight', 'net.20.bias', 'net.21.weight', 'net.21.bias', 'net.24.weight', 'net.24.bias', 'net.25.weight', 'net.25.bias', 'net.28.weight', 'net.28.bias', 'net.29.weight', 'net.29.bias', 'net.32.weight', 'net.32.bias', 'net.33.weight', 'net.33.bias', 'net.36.weight', 'net.36.bias'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow_proj_dict['state_dict'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "33e41c93-a66f-408c-a83f-42de293b4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flow_matching import FlowVelocityNet, flow_matching_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "15965811-502c-4d25-b172-f3ec97b2cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_proj = FlowVelocityNet(input_dim=3, hidden_dim=256, num_layers=8).to('cuda')\n",
    "flow_proj.load_state_dict(flow_proj_dict['state_dict'])\n",
    "flow_proj = flow_proj.to('cuda')\n",
    "flow_proj.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "79e35992-a885-464f-abef-8b98eacb5a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj_flow(x):\n",
    "    return flow_matching_projection(x, flow_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4cc86095-a4f3-4295-9372-124ca434aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train torch.Size([4000, 3])\n",
      "Y_train (4000, 3)\n",
      "X_val torch.Size([800, 3])\n",
      "Y_val (800, 3)\n",
      "X_test torch.Size([1200, 3])\n",
      "Y_test (1200, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1000305/1818339647.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(loaded['X_train'], dtype = torch.float32)\n",
      "/tmp/ipykernel_1000305/1818339647.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  assert torch.isfinite(torch.tensor(loaded[name])).all(), f\"Found NaN/Inf in {name}\"\n"
     ]
    }
   ],
   "source": [
    "loaded = torch.load(\"./../Data/sphere_dataset.pt\", map_location=\"cpu\", weights_only = False)\n",
    "\n",
    "for k, v in loaded.items():\n",
    "    try:\n",
    "        print(k, v.shape)\n",
    "    except AttributeError:\n",
    "        print(k, type(v))\n",
    "\n",
    "X_train = torch.tensor(loaded['X_train'], dtype = torch.float32)\n",
    "Y_train = torch.tensor(loaded['Y_train'], dtype = torch.float32)\n",
    "\n",
    "for name in [\"X_train\",\"Y_train\",\"X_val\",\"Y_val\",\"X_test\",\"Y_test\"]:\n",
    "    assert torch.isfinite(torch.tensor(loaded[name])).all(), f\"Found NaN/Inf in {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "42a54094-4d4d-44f2-8779-c956ba132ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1000305/832203245.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(loaded[\"X_train\"], dtype=torch.float32)\n",
      "/tmp/ipykernel_1000305/832203245.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val   = torch.tensor(loaded[\"X_val\"],   dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# tensors\n",
    "X_train = torch.tensor(loaded[\"X_train\"], dtype=torch.float32)\n",
    "Y_train = torch.tensor(loaded[\"Y_train\"], dtype=torch.float32)\n",
    "X_val   = torch.tensor(loaded[\"X_val\"],   dtype=torch.float32)\n",
    "Y_val   = torch.tensor(loaded[\"Y_val\"],   dtype=torch.float32)\n",
    "\n",
    "# # compute tau from TRAIN translations (no leakage)\n",
    "# G = X_train.view(-1, 4, 4)\n",
    "# t = G[:, :3, 3]\n",
    "# tau = t.std()   # scalar tensor\n",
    "\n",
    "# # normalize translation column (rows 0..2, col 3) in ALL splits\n",
    "# def normalize_se3_translation(X16: torch.Tensor, tau: torch.Tensor) -> torch.Tensor:\n",
    "#     G = X16.view(-1, 4, 4).clone()\n",
    "#     G[:, :3, 3] = G[:, :3, 3] / tau\n",
    "#     return G.view(-1, 16)\n",
    "\n",
    "# X_train_n = normalize_se3_translation(X_train, tau)\n",
    "# Y_train_n = normalize_se3_translation(Y_train, tau)\n",
    "# X_val_n   = normalize_se3_translation(X_val,   tau)\n",
    "# Y_val_n   = normalize_se3_translation(Y_val,   tau)\n",
    "\n",
    "# datasets (use normalized tensors)\n",
    "train_ds = TensorDataset(X_train, Y_train)\n",
    "val_ds   = TensorDataset(X_val, Y_val)\n",
    "\n",
    "# loaders\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "12483cf3-2397-4a74-aff8-37ad50079f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ProjectedFeedForward(3,3,3,proj_func = proj_flow, dropout = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "04914142-0089-4cc4-995b-684a56094427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train 3.669e-01 | val 3.289e-01 | lr 1.0e-03\n",
      "epoch   20 | train 1.190e-01 | val 1.172e-01 | lr 1.0e-03\n",
      "epoch   40 | train 8.880e-02 | val 8.906e-02 | lr 1.0e-03\n",
      "epoch   60 | train 7.462e-02 | val 7.368e-02 | lr 1.0e-03\n",
      "epoch   80 | train 6.268e-02 | val 6.159e-02 | lr 1.0e-03\n",
      "epoch  100 | train 4.974e-02 | val 4.528e-02 | lr 1.0e-03\n",
      "epoch  120 | train 4.385e-02 | val 3.952e-02 | lr 1.0e-03\n",
      "epoch  140 | train 4.011e-02 | val 3.475e-02 | lr 1.0e-03\n",
      "epoch  160 | train 3.543e-02 | val 3.015e-02 | lr 1.0e-03\n",
      "epoch  180 | train 3.081e-02 | val 2.786e-02 | lr 1.0e-03\n",
      "epoch  200 | train 2.849e-02 | val 2.723e-02 | lr 1.0e-03\n",
      "epoch  220 | train 2.666e-02 | val 2.674e-02 | lr 1.0e-03\n",
      "epoch  240 | train 2.486e-02 | val 2.536e-02 | lr 1.0e-03\n",
      "epoch  260 | train 2.522e-02 | val 2.509e-02 | lr 1.0e-03\n",
      "epoch  280 | train 2.247e-02 | val 2.206e-02 | lr 1.0e-03\n",
      "epoch  300 | train 2.298e-02 | val 2.247e-02 | lr 1.0e-03\n",
      "epoch  320 | train 2.261e-02 | val 2.213e-02 | lr 1.0e-03\n",
      "epoch  340 | train 2.143e-02 | val 2.219e-02 | lr 1.0e-03\n",
      "epoch  360 | train 2.087e-02 | val 2.105e-02 | lr 1.0e-03\n",
      "epoch  380 | train 2.092e-02 | val 2.227e-02 | lr 1.0e-03\n",
      "epoch  400 | train 1.947e-02 | val 2.173e-02 | lr 1.0e-03\n",
      "epoch  420 | train 2.075e-02 | val 2.349e-02 | lr 1.0e-03\n",
      "epoch  440 | train 1.951e-02 | val 2.119e-02 | lr 1.0e-03\n",
      "epoch  460 | train 2.029e-02 | val 2.070e-02 | lr 1.0e-03\n",
      "epoch  480 | train 1.945e-02 | val 2.102e-02 | lr 1.0e-03\n",
      "epoch  500 | train 1.829e-02 | val 2.182e-02 | lr 1.0e-03\n",
      "epoch  520 | train 1.795e-02 | val 2.045e-02 | lr 1.0e-03\n",
      "epoch  540 | train 1.797e-02 | val 2.075e-02 | lr 1.0e-03\n",
      "epoch  560 | train 1.811e-02 | val 2.041e-02 | lr 1.0e-03\n",
      "epoch  580 | train 1.877e-02 | val 2.135e-02 | lr 1.0e-03\n",
      "epoch  600 | train 1.791e-02 | val 2.349e-02 | lr 1.0e-03\n",
      "epoch  620 | train 1.809e-02 | val 1.977e-02 | lr 1.0e-03\n",
      "epoch  640 | train 1.713e-02 | val 2.034e-02 | lr 1.0e-03\n",
      "epoch  660 | train 1.803e-02 | val 1.915e-02 | lr 1.0e-03\n",
      "epoch  680 | train 1.737e-02 | val 2.051e-02 | lr 1.0e-03\n",
      "epoch  700 | train 1.730e-02 | val 1.944e-02 | lr 1.0e-03\n",
      "epoch  720 | train 1.748e-02 | val 1.880e-02 | lr 1.0e-03\n",
      "epoch  740 | train 1.611e-02 | val 1.962e-02 | lr 1.0e-03\n",
      "epoch  760 | train 1.644e-02 | val 1.877e-02 | lr 1.0e-03\n",
      "epoch  780 | train 1.732e-02 | val 1.821e-02 | lr 1.0e-03\n",
      "epoch  800 | train 1.714e-02 | val 1.881e-02 | lr 1.0e-03\n",
      "epoch  820 | train 1.625e-02 | val 1.706e-02 | lr 1.0e-03\n",
      "epoch  840 | train 1.605e-02 | val 1.730e-02 | lr 1.0e-03\n",
      "epoch  860 | train 1.631e-02 | val 2.198e-02 | lr 1.0e-03\n",
      "epoch  880 | train 1.663e-02 | val 1.747e-02 | lr 1.0e-03\n",
      "epoch  900 | train 1.646e-02 | val 1.814e-02 | lr 1.0e-03\n",
      "epoch  920 | train 1.542e-02 | val 1.909e-02 | lr 1.0e-03\n",
      "epoch  940 | train 1.589e-02 | val 1.758e-02 | lr 1.0e-03\n",
      "epoch  960 | train 1.528e-02 | val 1.765e-02 | lr 1.0e-03\n",
      "epoch  980 | train 1.601e-02 | val 1.649e-02 | lr 1.0e-03\n",
      "epoch 1000 | train 1.551e-02 | val 1.818e-02 | lr 1.0e-03\n"
     ]
    }
   ],
   "source": [
    "model, logs = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    lr=1e-3,\n",
    "    num_epochs=1000,\n",
    "    device='cuda',\n",
    "    weight_decay=0,\n",
    "    early_stop=0,      # disable early stopping\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a48b1bf8-819a-43e8-8ae0-0062d7380f9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msquare()\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/projects/gtml/Constrained Networks/src/Models/projected.py:184\u001b[0m, in \u001b[0;36mProjectedFeedForward.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# Internal projection BETWEEN blocks (i.e., after block i, before block i+1)\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_internal_projection \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_proj_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_proj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# ALWAYS apply final projection (identity if final_proj_func is None)\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_proj_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[143], line 2\u001b[0m, in \u001b[0;36mproj_flow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mproj_flow\u001b[39m(x):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflow_matching_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow_proj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/gtml/Constrained Networks/src/Models/flow_matching.py:276\u001b[0m, in \u001b[0;36mflow_matching_projection\u001b[0;34m(x, flow_model, T, num_steps, differentiable)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03mGeneric flow matching projection function.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m    Projected points on the learned manifold, same shape as input\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mflow_matching_projection_differentiable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# Convert to numpy, apply scipy projection, convert back\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     original_shape \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/projects/gtml/Constrained Networks/src/Models/flow_matching.py:154\u001b[0m, in \u001b[0;36mflow_matching_projection_differentiable\u001b[0;34m(x, flow_model, T, num_steps)\u001b[0m\n\u001b[1;32m    149\u001b[0m inp \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x_current, t_tensor], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# [N, input_dim + 1]\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Get velocity from flow matching model\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# Note: We use no_grad here because the flow_model should be pre-trained\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# If you want to train it jointly, remove the no_grad()\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mflow_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [N, input_dim]\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# Euler step: x = x - v * dt (negative for time-reversed flow)\u001b[39;00m\n\u001b[1;32m    157\u001b[0m x_current \u001b[38;5;241m=\u001b[39m x_current \u001b[38;5;241m-\u001b[39m v \u001b[38;5;241m*\u001b[39m dt\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/projects/gtml/Constrained Networks/src/Models/flow_matching.py:92\u001b[0m, in \u001b[0;36mFlowVelocityNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Forward pass through the velocity network.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m        Velocity vector of shape [batch_size, input_dim]\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "(model.to('cpu')(X_train.to('cpu')).square().sum(dim=1) - 1).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40fe3611-753f-4b4c-91ce-2a91887c14d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0.grad is None?  False\n",
      "||x0.grad||:       5.557411193847656\n",
      "max |grad|:        1.9498889446258545\n"
     ]
    }
   ],
   "source": [
    "x0 = X_train[:8].to('cuda').clone().requires_grad_(True)   # pick a tiny batch\n",
    "y  = proj_flow(x0)\n",
    "\n",
    "loss = (y**2).sum()   # any scalar function works\n",
    "loss.backward()\n",
    "\n",
    "print(\"x0.grad is None? \", x0.grad is None)\n",
    "print(\"||x0.grad||:      \", x0.grad.norm().item())\n",
    "print(\"max |grad|:       \", x0.grad.abs().max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8a1bd368-45bb-48be-87a8-ffbd6e2d47b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autograd: 0.7022574543952942\n",
      "fd:       0.8332699537277222\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-2\n",
    "i = 0  # one sample\n",
    "j = 0  # one coordinate\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "x0 = X_train[:2].to(device).clone().requires_grad_(True)\n",
    "y  = proj_flow(x0+torch.randn_like(x0))\n",
    "f  = y[0,0]            # scalar\n",
    "f.backward()\n",
    "g_autograd = x0.grad[i,j].item()\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_plus = x0.detach().clone()\n",
    "    x_minus = x0.detach().clone()\n",
    "    x_plus[i,j] += eps\n",
    "    x_minus[i,j] -= eps\n",
    "    f_plus  = proj_flow(x_plus)[0,0].item()\n",
    "    f_minus = proj_flow(x_minus)[0,0].item()\n",
    "g_fd = (f_plus - f_minus)/(2*eps)\n",
    "\n",
    "print(\"autograd:\", g_autograd)\n",
    "print(\"fd:      \", g_fd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3065a4a-fb2d-4677-9be3-f244979765f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be55ea-de9c-4685-9c04-5ca77a0b0817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
