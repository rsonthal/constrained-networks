{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd0cb17-40c3-4c3f-94c4-8988fc97a089",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15299f55-9574-42ad-8823-ada341609496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from regular import RegularTransformer, RegularFeedForward\n",
    "from projected import ProjectedTransformer, ProjectedFeedForward\n",
    "from exponential import ExponentialTransformer, ExponentialFeedForward\n",
    "from train_constrained import train_model\n",
    "import projections\n",
    "import exponentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814ee082-4382-4a66-9bc8-216e1727052e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (4000, 10, 9)\n",
      "Y_train (4000, 10, 9)\n",
      "X_val (800, 10, 9)\n",
      "Y_val (800, 10, 9)\n",
      "X_test (1200, 10, 9)\n",
      "Y_test (1200, 10, 9)\n"
     ]
    }
   ],
   "source": [
    "loaded = torch.load(\"./../Data/cs_dataset.pt\", map_location=\"cpu\", weights_only = False)\n",
    "\n",
    "for k, v in loaded.items():\n",
    "    try:\n",
    "        print(k, v.shape)\n",
    "    except AttributeError:\n",
    "        print(k, type(v))\n",
    "\n",
    "X_train = torch.tensor(loaded['X_train'], dtype = torch.float32)\n",
    "Y_train = torch.tensor(loaded['Y_train'], dtype = torch.float32)\n",
    "\n",
    "for name in [\"X_train\",\"Y_train\",\"X_val\",\"Y_val\",\"X_test\",\"Y_test\"]:\n",
    "    assert torch.isfinite(torch.tensor(loaded[name])).all(), f\"Found NaN/Inf in {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1e685b2-0764-4b97-85bc-7f159f966243",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RegularTransformer(\n",
    "                input_dim=9,\n",
    "                nhead=3,\n",
    "                d_hid=128,\n",
    "                nlayers=2,\n",
    "                dropout=0,\n",
    "                dt=1,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a15ec37-def8-4e94-956f-19b45971b873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 10, 9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43da8acd-05b9-4810-90a6-29ba6d23bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Testing projected transformer on CS dataset (via train_ff.py)\n",
      "============================================================\n",
      "\n",
      "/projects/gtml/Constrained Networks/src/Data/cs_dataset.pt\n",
      "torch.Size([4000, 10, 9])\n",
      "Epoch      1 | train_loss=6.719520e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      2 | train_loss=6.719520e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      3 | train_loss=6.719520e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      4 | train_loss=6.719519e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      5 | train_loss=6.719519e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      6 | train_loss=6.719520e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      7 | train_loss=6.719519e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      8 | train_loss=6.719519e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch      9 | train_loss=6.719520e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "Epoch     10 | train_loss=6.719520e-01 | val_loss=6.743161e-01 | lr=1.000e-03\n",
      "\n",
      "Saved best checkpoint (epoch=1, best_val=6.743161e-01) to: outputs/cs/projected/depth2/out9/lr0.001_wd0.0001/seed0\n",
      "\n",
      "✓ projected completed successfully\n",
      "\n",
      "============================================================\n",
      "Testing regular transformer on CS dataset (via train_ff.py)\n",
      "============================================================\n",
      "\n",
      "/projects/gtml/Constrained Networks/src/Data/cs_dataset.pt\n",
      "torch.Size([4000, 10, 9])\n",
      "Epoch      1 | train_loss=4.316784e-01 | val_loss=4.340650e-01 | lr=1.000e-03\n",
      "Epoch      2 | train_loss=3.562546e-01 | val_loss=3.574283e-01 | lr=1.000e-03\n",
      "Epoch      3 | train_loss=3.390837e-01 | val_loss=3.397407e-01 | lr=1.000e-03\n",
      "Epoch      4 | train_loss=3.357513e-01 | val_loss=3.359558e-01 | lr=1.000e-03\n",
      "Epoch      5 | train_loss=3.347973e-01 | val_loss=3.349866e-01 | lr=1.000e-03\n",
      "Epoch      6 | train_loss=3.345909e-01 | val_loss=3.345352e-01 | lr=1.000e-03\n",
      "Epoch      7 | train_loss=3.341179e-01 | val_loss=3.345276e-01 | lr=1.000e-03\n",
      "Epoch      8 | train_loss=3.339575e-01 | val_loss=3.345561e-01 | lr=1.000e-03\n",
      "Epoch      9 | train_loss=3.334671e-01 | val_loss=3.338496e-01 | lr=1.000e-03\n",
      "Epoch     10 | train_loss=3.343140e-01 | val_loss=3.345867e-01 | lr=1.000e-03\n",
      "\n",
      "Saved best checkpoint (epoch=9, best_val=3.338496e-01) to: outputs/cs/regular/depth2/out9/lr0.001_wd0.0001/seed0\n",
      "\n",
      "✓ regular completed successfully\n",
      "\n",
      "============================================================\n",
      "Testing exponential transformer on CS dataset (via train_ff.py)\n",
      "============================================================\n",
      "\n",
      "/projects/gtml/Constrained Networks/src/Data/cs_dataset.pt\n",
      "torch.Size([4000, 10, 9])\n",
      "Epoch      1 | train_loss=6.458219e-01 | val_loss=6.478730e-01 | lr=1.000e-03\n",
      "Epoch      2 | train_loss=6.467375e-01 | val_loss=6.477726e-01 | lr=1.000e-03\n",
      "Epoch      3 | train_loss=6.407210e-01 | val_loss=6.425651e-01 | lr=1.000e-03\n",
      "Epoch      4 | train_loss=6.401823e-01 | val_loss=6.415979e-01 | lr=1.000e-03\n",
      "Epoch      5 | train_loss=6.397175e-01 | val_loss=6.441905e-01 | lr=1.000e-03\n",
      "Epoch      6 | train_loss=6.397260e-01 | val_loss=6.413133e-01 | lr=1.000e-03\n",
      "Epoch      7 | train_loss=6.391254e-01 | val_loss=6.426182e-01 | lr=1.000e-03\n",
      "Epoch      8 | train_loss=6.384505e-01 | val_loss=6.418702e-01 | lr=1.000e-03\n",
      "Epoch      9 | train_loss=6.359531e-01 | val_loss=6.387245e-01 | lr=1.000e-03\n",
      "Epoch     10 | train_loss=6.367150e-01 | val_loss=6.414210e-01 | lr=1.000e-03\n",
      "\n",
      "Saved best checkpoint (epoch=9, best_val=6.387245e-01) to: outputs/cs/exponential/depth2/out3/lr0.001_wd0.0001/seed0\n",
      "\n",
      "✓ exponential completed successfully\n",
      "\n",
      "============================================================\n",
      "Testing probabilistic transformer on CS dataset (via train_ff.py)\n",
      "============================================================\n",
      "\n",
      "/projects/gtml/Constrained Networks/src/Data/cs_dataset.pt\n",
      "torch.Size([4000, 10, 9])\n",
      "--- Creating Anchors: Sampling 50 from Training Data ---\n",
      "Created 50 anchors with shape (50, 9)\n",
      "--- Generating Labels (Voronoi Partitioning) ---\n",
      "    Training Data (T): 40000\n",
      "    Anchors/Particles (N): 50\n",
      "    Done. Created DataLoader with 400 batches.\n",
      "epoch    1 | train 9.790e-01 | val 3.332e-01 | lr 1.0e-03\n",
      "\n",
      "Saved best checkpoint (epoch=7, best_val=3.324562e-01) to: outputs/cs/probabilistic/depth2/out9/anchors50/lr0.001_wd0.0001/seed0\n",
      "\n",
      "✓ probabilistic completed successfully\n",
      "\n",
      "============================================================\n",
      "Testing flow_matching transformer on CS dataset (via train_ff.py)\n",
      "============================================================\n",
      "\n",
      "/projects/gtml/Constrained Networks/src/Data/cs_dataset.pt\n",
      "torch.Size([4000, 10, 9])\n",
      "Loaded flow matching model from outputsflow/cs_dataset/BEST/model.pt (input_dim=9)\n",
      "Epoch      1 | train_loss=4.503547e-01 | val_loss=4.527183e-01 | lr=1.000e-03\n",
      "Epoch      2 | train_loss=4.094015e-01 | val_loss=4.110125e-01 | lr=1.000e-03\n",
      "Epoch      3 | train_loss=3.994583e-01 | val_loss=4.011995e-01 | lr=1.000e-03\n",
      "Epoch      4 | train_loss=3.943457e-01 | val_loss=3.960145e-01 | lr=1.000e-03\n",
      "Epoch      5 | train_loss=3.917799e-01 | val_loss=3.939691e-01 | lr=1.000e-03\n",
      "Epoch      6 | train_loss=3.912952e-01 | val_loss=3.933849e-01 | lr=1.000e-03\n",
      "Epoch      7 | train_loss=3.889839e-01 | val_loss=3.909823e-01 | lr=1.000e-03\n",
      "Epoch      8 | train_loss=3.903975e-01 | val_loss=3.914141e-01 | lr=1.000e-03\n",
      "Epoch      9 | train_loss=3.866101e-01 | val_loss=3.886454e-01 | lr=1.000e-03\n",
      "Epoch     10 | train_loss=3.857370e-01 | val_loss=3.884997e-01 | lr=1.000e-03\n",
      "\n",
      "Saved best checkpoint (epoch=10, best_val=3.884997e-01) to: outputs/cs/flow_matching/depth2/out9/lr0.001_wd0.0001/seed0\n",
      "\n",
      "✓ flow_matching completed successfully\n"
     ]
    }
   ],
   "source": [
    "model_types = [\"projected\", \"regular\", \"exponential\", \"probabilistic\", \"flow_matching\"]\n",
    "\n",
    "for model_type in model_types:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Testing {model_type} transformer on CS dataset (via train_ff.py)\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    cmd = [\n",
    "        sys.executable, \"train_ff.py\",\n",
    "        \"--model_type\", model_type,\n",
    "        \"--dataset\", \"cs\",\n",
    "        \"--depth\", \"2\",\n",
    "        \"--num_epochs\", \"10\",\n",
    "        \"--batch_size\", \"100\",\n",
    "        \"--eval_every\", \"1\",\n",
    "        \"--lr\", \"1e-3\",\n",
    "        \"--device\", \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"--residual\",\n",
    "    ]\n",
    "    \n",
    "    # Use internal projections/exponentials for these model types\n",
    "    if model_type in [\"exponential\", \"projected\", \"flow_matching\"]:\n",
    "        cmd.append(\"--use_internal\")\n",
    "    \n",
    "    if model_type == \"probabilistic\":\n",
    "        cmd.extend([\"--num_anchors\", \"50\"])\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True, cwd=Path.cwd())\n",
    "        print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"STDERR:\", result.stderr)\n",
    "        print(f\"✓ {model_type} completed successfully\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"✗ {model_type} failed with return code {e.returncode}\")\n",
    "        print(\"STDOUT:\", e.stdout)\n",
    "        print(\"STDERR:\", e.stderr)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"⚠ train_ff.py not found - please check the file path\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
