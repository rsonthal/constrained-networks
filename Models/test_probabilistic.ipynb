{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "463c1241-ed77-4e8e-877a-3424782cb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98999b46-21e8-4391-b810-018ebee2ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from scipy.spatial.distance import cdist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2403b0ea-71d8-4e20-a6f8-ba95ae1bee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probabilistic import (\n",
    "    create_label_dataset,\n",
    "    create_anchors,\n",
    "    probabilistic_transformer_loss,\n",
    "    predict,\n",
    "    sample_sphere,\n",
    "    sample_so3,\n",
    "    sample_se3,\n",
    "    train_probabilistic_model\n",
    ")\n",
    "from train_constrained import train_model\n",
    "from regular import RegularTransformer, RegularFeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f08b690-e40f-40cb-8b92-606181d594bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_so3(X: torch.Tensor, atol: float = 1e-3):\n",
    "    assert X.dim() == 2 and X.shape[1] == 9\n",
    "    R = X.view(-1, 3, 3)\n",
    "\n",
    "    I = torch.eye(3, device=R.device, dtype=R.dtype).expand(R.shape[0], 3, 3)\n",
    "    ortho_err = torch.linalg.norm(R.transpose(-1, -2) @ R - I, dim=(-2, -1))  # (B,)\n",
    "    det_err = torch.abs(torch.linalg.det(R) - 1.0)                            # (B,)\n",
    "\n",
    "    ok = (ortho_err <= atol) & (det_err <= atol)\n",
    "    return {\"ok\": ok, \"ortho_err\": ortho_err, \"det_err\": det_err}\n",
    "\n",
    "def check_so3_flat(R9: torch.Tensor, tol: float = 1e-4):\n",
    "    \"\"\"\n",
    "    R9: [B, 9] or [B, S, 9]\n",
    "    Returns: (ok_mask, max_orth_err, max_det_err)\n",
    "    \"\"\"\n",
    "    orig = R9.shape\n",
    "    if R9.dim() == 3:\n",
    "        B, S, _ = orig\n",
    "        R = R9.reshape(B*S, 3, 3)\n",
    "    else:\n",
    "        B = orig[0]\n",
    "        R = R9.reshape(B, 3, 3)\n",
    "\n",
    "    I = torch.eye(3, device=R.device, dtype=R.dtype).expand(R.shape[0], 3, 3)\n",
    "    orth_err = torch.linalg.norm(R.transpose(-1, -2) @ R - I, dim=(-2, -1))\n",
    "    det_err  = torch.abs(torch.linalg.det(R) - 1.0)\n",
    "\n",
    "    ok = (orth_err <= tol) & (det_err <= tol)\n",
    "    if R9.dim() == 3:\n",
    "        ok = ok.reshape(B, S)\n",
    "\n",
    "    return ok, orth_err.max().item(), det_err.max().item()\n",
    "\n",
    "\n",
    "def check_se3_flat(G16: torch.Tensor, tol_R: float = 1e-4, tol_last: float = 1e-6):\n",
    "    \"\"\"\n",
    "    G16: [B, 16] (row-major flatten of 4x4).\n",
    "    Checks:\n",
    "      - top-left 3x3 is in SO(3) (via check_so3_flat)\n",
    "      - last row equals [0,0,0,1]\n",
    "    Returns: dict with masks + max errors.\n",
    "    \"\"\"\n",
    "    B = G16.shape[0]\n",
    "    G = G16.reshape(B, 4, 4)\n",
    "\n",
    "    R = G[:, :3, :3].reshape(B, 9)          # [B,9]\n",
    "    ok_R, max_orth, max_det = check_so3_flat(R, tol=tol_R)\n",
    "\n",
    "    last = G[:, 3, :]                        # [B,4]\n",
    "    target = torch.tensor([0., 0., 0., 1.], device=G.device, dtype=G.dtype).expand_as(last)\n",
    "    last_err = torch.max(torch.abs(last - target), dim=-1).values  # [B]\n",
    "    ok_last = last_err <= tol_last\n",
    "\n",
    "    ok_all = ok_R & ok_last\n",
    "\n",
    "    return dict(\n",
    "        ok=ok_all,\n",
    "        ok_R=ok_R,\n",
    "        ok_last_row=ok_last,\n",
    "        max_orth_err=max_orth,\n",
    "        max_det_err=max_det,\n",
    "        max_last_row_err=last_err.max().item(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddbe2ca-a5c8-4fd2-b564-5fc2e8087c6d",
   "metadata": {},
   "source": [
    "# Test Probabilistic Model on SO(3) and SE(3) Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e5f6d91-4c3e-4f75-b59d-f4faf35da491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (4000, 16)\n",
      "Y_train (4000, 16)\n",
      "X_val (800, 16)\n",
      "Y_val (800, 16)\n",
      "X_test (1200, 16)\n",
      "Y_test (1200, 16)\n"
     ]
    }
   ],
   "source": [
    "loaded = torch.load(\"./../Data/protein_dataset.pt\", map_location=\"cpu\", weights_only = False)\n",
    "\n",
    "for k, v in loaded.items():\n",
    "    try:\n",
    "        print(k, v.shape)\n",
    "    except AttributeError:\n",
    "        print(k, type(v))\n",
    "\n",
    "X_train = torch.tensor(loaded['X_train'], dtype = torch.float32)\n",
    "Y_train = torch.tensor(loaded['Y_train'], dtype = torch.float32)\n",
    "\n",
    "for name in [\"X_train\",\"Y_train\",\"X_val\",\"Y_val\",\"X_test\",\"Y_test\"]:\n",
    "    assert torch.isfinite(torch.tensor(loaded[name])).all(), f\"Found NaN/Inf in {name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "934dd6ac-ccb2-4c88-b8e1-3c9044365b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Anchors: Sampling 100 from Training Data ---\n",
      "Created 100 anchors with shape (100, 16)\n",
      "torch.Size([100, 16])\n"
     ]
    }
   ],
   "source": [
    "# Create anchors from training data (recommended approach)\n",
    "num_anchors = 100\n",
    "Y_train_np = Y_train.numpy()\n",
    "anchors = create_anchors(num_anchors, training_data=Y_train_np, manifold='se3')\n",
    "# anchors = create_anchors(num_anchors, manifold='se3')\n",
    "anchors_tensor = torch.tensor(anchors, dtype=torch.float32)\n",
    "print(f\"Created {num_anchors} anchors with shape {anchors.shape}\")\n",
    "print(anchors_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1b556064-0c73-4dba-b2b7-e342481bf672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) 3.2167184826903394e-07 2.384185791015625e-07 0.0\n"
     ]
    }
   ],
   "source": [
    "# Verify anchors are valid SE(3)\n",
    "# out = check_so3(anchors_tensor)\n",
    "# print(out[\"ok\"].float().mean(), out[\"ortho_err\"].max(), out[\"det_err\"].max())\n",
    "\n",
    "out = check_se3_flat(anchors_tensor, tol_R=1e-4, tol_last=1e-6)\n",
    "print(out[\"ok\"].float().mean(), out[\"max_orth_err\"], out[\"max_det_err\"], out[\"max_last_row_err\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "193fdfab-3700-412d-b17f-67b1aff1a1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Labels (Voronoi Partitioning) ---\n",
      "    Training Data (T): 4000\n",
      "    Anchors/Particles (N): 100\n",
      "    Done. Created DataLoader with 8 batches.\n",
      "Created training loader with 8 batches\n",
      "Label tensor shape: torch.Size([4000]), unique labels: 100\n"
     ]
    }
   ],
   "source": [
    "# Create label dataset using Voronoi partitioning\n",
    "X_train_np = X_train.numpy()\n",
    "Y_train_np = Y_train.numpy()\n",
    "\n",
    "train_loader, L_train = create_label_dataset(\n",
    "    X_train_np, \n",
    "    Y_train_np, \n",
    "    anchors, \n",
    "    batch_size=500, \n",
    "    metric='euclidean'\n",
    ")\n",
    "print(f\"Created training loader with {len(train_loader)} batches\")\n",
    "print(f\"Label tensor shape: {L_train.shape}, unique labels: {L_train.unique().numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9af6aadd-4e22-4325-bf83-d46e7944ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val   = torch.tensor(loaded[\"X_val\"],   dtype=torch.float32)\n",
    "Y_val   = torch.tensor(loaded[\"Y_val\"],   dtype=torch.float32)\n",
    "\n",
    "# datasets\n",
    "val_ds   = TensorDataset(X_val, Y_val)\n",
    "\n",
    "# loaders\n",
    "batch_size = 256  # change if you want\n",
    "\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ef5f736d-45af-4a1b-9eef-2f94169def89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(RegularFeedForward(16,16,3,dropout=0.0), nn.Linear(16,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cc101678-85fe-48dd-acd5-b29009996c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7833c2f1-dadf-4694-8481-dc3e3b27639e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 100])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "228986e4-6cee-4393-8f4d-9c85085b0c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    1 | train 1.969e+00 | val 4.896e+06 | lr 1.0e-03\n",
      "epoch   20 | train 1.948e+00 | val 4.235e+06 | lr 1.0e-03\n",
      "epoch   40 | train 1.948e+00 | val 4.589e+06 | lr 1.0e-03\n",
      "epoch   60 | train 1.939e+00 | val 4.425e+06 | lr 1.0e-03\n",
      "epoch   80 | train 1.961e+00 | val 5.660e+06 | lr 1.0e-03\n",
      "epoch  100 | train 1.940e+00 | val 4.651e+06 | lr 1.0e-03\n",
      "epoch  120 | train 1.920e+00 | val 3.708e+06 | lr 1.0e-03\n",
      "epoch  140 | train 1.941e+00 | val 3.754e+06 | lr 1.0e-03\n",
      "epoch  160 | train 1.942e+00 | val 3.939e+06 | lr 1.0e-03\n",
      "epoch  180 | train 1.961e+00 | val 4.071e+06 | lr 1.0e-03\n",
      "epoch  200 | train 1.958e+00 | val 3.931e+06 | lr 1.0e-03\n",
      "epoch  220 | train 1.955e+00 | val 3.861e+06 | lr 1.0e-03\n",
      "epoch  240 | train 1.957e+00 | val 4.077e+06 | lr 1.0e-03\n",
      "epoch  260 | train 1.957e+00 | val 4.082e+06 | lr 1.0e-03\n",
      "epoch  280 | train 1.957e+00 | val 4.095e+06 | lr 1.0e-03\n",
      "epoch  300 | train 1.957e+00 | val 4.104e+06 | lr 1.0e-03\n",
      "epoch  320 | train 1.957e+00 | val 4.102e+06 | lr 1.0e-03\n",
      "epoch  340 | train 1.957e+00 | val 4.030e+06 | lr 1.0e-03\n",
      "epoch  360 | train 1.957e+00 | val 4.065e+06 | lr 1.0e-03\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_probabilistic_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43manchors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manchors_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# disable early stopping\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/projects/gtml/Constrained Networks/src/Models/probabilistic.py:278\u001b[0m, in \u001b[0;36mtrain_probabilistic_model\u001b[0;34m(model, train_loader, val_loader, anchors, lr, num_epochs, device, weight_decay, grad_clip, scheduler_patience, scheduler_factor, early_stop, verbose)\u001b[0m\n\u001b[1;32m    276\u001b[0m tr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    277\u001b[0m n_tr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m    279\u001b[0m     x, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m    280\u001b[0m     x, labels \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/utils/data/dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/utils/data/dataset.py:207\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.9/site-packages/torch/utils/data/dataset.py:207\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model, logs = train_probabilistic_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    anchors=anchors_tensor,\n",
    "    lr=1e-3,\n",
    "    num_epochs=1000,\n",
    "    device='cuda',\n",
    "    weight_decay=0,\n",
    "    early_stop=0,      # disable early stopping\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df904d3-1571-4130-ae74-f597c9a593b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anchors from training data\n",
    "num_anchors = 100\n",
    "Y_train_np = Y_train.numpy()\n",
    "anchors = create_anchors(num_anchors, training_data=Y_train_np, manifold='sphere')\n",
    "anchors_tensor = torch.tensor(anchors, dtype=torch.float32)\n",
    "print(f\"Created {num_anchors} anchors with shape {anchors.shape}\")\n",
    "\n",
    "# Verify anchors are on sphere\n",
    "anchor_norms = torch.linalg.norm(anchors_tensor, dim=1)\n",
    "print(f\"Anchor norm stats: min={anchor_norms.min():.6f}, max={anchor_norms.max():.6f}, mean={anchor_norms.mean():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bca00b-3d0c-427d-ba21-e39d6bed11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label dataset\n",
    "X_train_np = X_train.numpy()\n",
    "Y_train_np = Y_train.numpy()\n",
    "\n",
    "train_loader, L_train = create_label_dataset(\n",
    "    X_train_np, \n",
    "    Y_train_np, \n",
    "    anchors, \n",
    "    batch_size=256, \n",
    "    metric='euclidean'\n",
    ")\n",
    "print(f\"Created training loader with {len(train_loader)} batches\")\n",
    "print(f\"Label tensor shape: {L_train.shape}, unique labels: {L_train.unique().numel()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc056e98-f53f-4bfa-baa6-043eddccfcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation loader\n",
    "X_val_np = torch.tensor(loaded[\"X_val\"], dtype=torch.float32).numpy()\n",
    "Y_val_np = torch.tensor(loaded[\"Y_val\"], dtype=torch.float32).numpy()\n",
    "\n",
    "val_distances = cdist(Y_val_np, anchors, metric='euclidean')\n",
    "val_labels = torch.tensor(np.argmin(val_distances, axis=1), dtype=torch.long)\n",
    "\n",
    "val_ds = TensorDataset(\n",
    "    torch.tensor(X_val_np, dtype=torch.float32),\n",
    "    val_labels\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, drop_last=False)\n",
    "print(f\"Created validation loader with {len(val_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3871ef96-0a7f-40d4-986c-ebc841974257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created: input_dim=3, num_anchors=100\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "input_dim = X_train.shape[1]  # 3 for sphere input\n",
    "output_dim = Y_train.shape[1]  # 3 for sphere output\n",
    "\n",
    "model = ProbabilisticFeedForward(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=128,\n",
    "    num_layers=4,\n",
    "    num_anchors=num_anchors,\n",
    "    dropout=0.1\n",
    ")\n",
    "print(f\"Model created: input_dim={input_dim}, num_anchors={num_anchors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6bd98ae0-cb70-4262-b564-f6aa7d0a924d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_probabilistic_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43manchors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manchors_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# disable early stopping\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 18\u001b[0m, in \u001b[0;36mtrain_probabilistic_model\u001b[0;34m(model, train_loader, val_loader, anchors, lr, num_epochs, device, weight_decay, grad_clip, scheduler_patience, scheduler_factor, early_stop, verbose)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_probabilistic_model\u001b[39m(\n\u001b[1;32m      3\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m      4\u001b[0m     train_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m ):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     anchors \u001b[38;5;241m=\u001b[39m anchors\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m     opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/cuda/__init__.py:372\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    371\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    376\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model, logs = train_probabilistic_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    anchors=anchors_tensor,\n",
    "    lr=1e-3,\n",
    "    num_epochs=1000,\n",
    "    device='cuda',\n",
    "    weight_decay=0,\n",
    "    early_stop=0,      # disable early stopping\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b0445c4-2572-4ac2-b20e-d60000fb67ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test prediction\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m anchors_cuda \u001b[38;5;241m=\u001b[39m anchors_tensor\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m predict(model, X_test, anchors_cuda, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpectation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/cuda/__init__.py:372\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    371\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    376\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Test prediction\n",
    "model.eval()\n",
    "X_test = X_train[:100].to('cuda')\n",
    "anchors_cuda = anchors_tensor.to('cuda')\n",
    "\n",
    "Y_pred = predict(model, X_test, anchors_cuda, method='expectation')\n",
    "print(f\"Prediction shape: {Y_pred.shape}\")\n",
    "\n",
    "# Check if predictions are on sphere\n",
    "pred_norms = torch.linalg.norm(Y_pred, dim=1)\n",
    "print(f\"Prediction norm stats: min={pred_norms.min():.6f}, max={pred_norms.max():.6f}, mean={pred_norms.mean():.6f}\")\n",
    "print(f\"Predictions on sphere (within 1e-3): {(torch.abs(pred_norms - 1.0) < 1e-3).float().mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dec48c82-9406-4e5f-8a01-2812112cac26",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check for NaN/Inf\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Y_pred_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mY_pred\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misfinite(Y_pred_cpu)\u001b[38;5;241m.\u001b[39mall(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound NaN/Inf in predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll predictions are finite ✓\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Check for NaN/Inf\n",
    "Y_pred_cpu = Y_pred.cpu()\n",
    "assert torch.isfinite(Y_pred_cpu).all(), \"Found NaN/Inf in predictions\"\n",
    "print(\"All predictions are finite ✓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f0e7f25-10f1-4f7e-b15a-9f67360e72cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compare expectation vs argmax prediction methods\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Y_pred_expectation \u001b[38;5;241m=\u001b[39m predict(model, \u001b[43mX_test\u001b[49m, anchors_cuda, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpectation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m Y_pred_argmax \u001b[38;5;241m=\u001b[39m predict(model, X_test, anchors_cuda, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m expectation_norms \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(Y_pred_expectation, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare expectation vs argmax prediction methods\n",
    "Y_pred_expectation = predict(model, X_test, anchors_cuda, method='expectation')\n",
    "Y_pred_argmax = predict(model, X_test, anchors_cuda, method='argmax')\n",
    "\n",
    "expectation_norms = torch.linalg.norm(Y_pred_expectation, dim=1)\n",
    "argmax_norms = torch.linalg.norm(Y_pred_argmax, dim=1)\n",
    "\n",
    "print(f\"Expectation method - norm stats: min={expectation_norms.min():.6f}, max={expectation_norms.max():.6f}, mean={expectation_norms.mean():.6f}\")\n",
    "print(f\"Argmax method - norm stats: min={argmax_norms.min():.6f}, max={argmax_norms.max():.6f}, mean={argmax_norms.mean():.6f}\")\n",
    "print(f\"Argmax on sphere (within 1e-3): {(torch.abs(argmax_norms - 1.0) < 1e-3).float().mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e074aadf-3bc8-4cda-815a-82225927322b",
   "metadata": {},
   "source": [
    "# Test on SO(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a64bdc3a-d072-4b28-8132-67617c6fe85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (4000, 9)\n",
      "Y_train (4000, 9)\n",
      "X_val (800, 9)\n",
      "Y_val (800, 9)\n",
      "X_test (1200, 9)\n",
      "Y_test (1200, 9)\n"
     ]
    }
   ],
   "source": [
    "loaded = torch.load(\"./../Data/so3_dataset.pt\", map_location=\"cpu\", weights_only = False)\n",
    "\n",
    "for k, v in loaded.items():\n",
    "    try:\n",
    "        print(k, v.shape)\n",
    "    except AttributeError:\n",
    "        print(k, type(v))\n",
    "\n",
    "X_train = torch.tensor(loaded['X_train'], dtype = torch.float32)\n",
    "Y_train = torch.tensor(loaded['Y_train'], dtype = torch.float32)\n",
    "\n",
    "for name in [\"X_train\",\"Y_train\",\"X_val\",\"Y_val\",\"X_test\",\"Y_test\"]:\n",
    "    assert torch.isfinite(torch.tensor(loaded[name])).all(), f\"Found NaN/Inf in {name}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea8fbb2c-0964-49d1-8950-2b657dbebf8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4000, 4, 4]' is invalid for input of size 36000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check that Y_train is valid SE(3)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_se3_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol_R\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_train SE(3) validity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax ortho err: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_orth_err\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Max det err: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_det_err\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Max last row err: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_last_row_err\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mcheck_se3_flat\u001b[0;34m(G16, tol_R, tol_last)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mG16: [B, 16] (row-major flatten of 4x4).\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mChecks:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mReturns: dict with masks + max errors.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m B \u001b[38;5;241m=\u001b[39m G16\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 45\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mG16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m R \u001b[38;5;241m=\u001b[39m G[:, :\u001b[38;5;241m3\u001b[39m, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, \u001b[38;5;241m9\u001b[39m)          \u001b[38;5;66;03m# [B,9]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ok_R, max_orth, max_det \u001b[38;5;241m=\u001b[39m check_so3_flat(R, tol\u001b[38;5;241m=\u001b[39mtol_R)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[4000, 4, 4]' is invalid for input of size 36000"
     ]
    }
   ],
   "source": [
    "# Check that Y_train is valid SE(3)\n",
    "out = check_se3_flat(Y_train, tol_R=1e-4, tol_last=1e-6)\n",
    "print(f\"Y_train SE(3) validity: {out['ok'].float().mean():.4f}\")\n",
    "print(f\"Max ortho err: {out['max_orth_err']:.6e}, Max det err: {out['max_det_err']:.6e}, Max last row err: {out['max_last_row_err']:.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef5076aa-62a3-4291-ba98-9b89f720019d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train SO(3) validity: 1.0000\n",
      "Max ortho err: 2.109975e-07, Max det err: 2.384186e-07\n"
     ]
    }
   ],
   "source": [
    "# Check that X_train is valid SO(3)\n",
    "out = check_so3(X_train, atol=1e-5)\n",
    "print(f\"X_train SO(3) validity: {out['ok'].float().mean():.4f}\")\n",
    "print(f\"Max ortho err: {out['ortho_err'].max():.6e}, Max det err: {out['det_err'].max():.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8abf7a90-caf2-446c-b7f5-1723c6d6cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating Anchors: Sampling 100 from Training Data ---\n",
      "Created 100 anchors with shape (100, 9)\n"
     ]
    }
   ],
   "source": [
    "# Create anchors from training data (recommended approach)\n",
    "num_anchors = 100\n",
    "Y_train_np = Y_train.numpy()\n",
    "anchors = create_anchors(num_anchors, training_data=Y_train_np, manifold='se3')\n",
    "anchors_tensor = torch.tensor(anchors, dtype=torch.float32)\n",
    "print(f\"Created {num_anchors} anchors with shape {anchors.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2902582d-a776-4593-9607-e95d428ed7c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[100, 4, 4]' is invalid for input of size 900",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Verify anchors are valid SE(3)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_se3_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43manchors_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol_R\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnchors SE(3) validity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax ortho err: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_orth_err\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Max det err: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_det_err\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Max last row err: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_last_row_err\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 45\u001b[0m, in \u001b[0;36mcheck_se3_flat\u001b[0;34m(G16, tol_R, tol_last)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03mG16: [B, 16] (row-major flatten of 4x4).\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mChecks:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mReturns: dict with masks + max errors.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m B \u001b[38;5;241m=\u001b[39m G16\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 45\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mG16\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m R \u001b[38;5;241m=\u001b[39m G[:, :\u001b[38;5;241m3\u001b[39m, :\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, \u001b[38;5;241m9\u001b[39m)          \u001b[38;5;66;03m# [B,9]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m ok_R, max_orth, max_det \u001b[38;5;241m=\u001b[39m check_so3_flat(R, tol\u001b[38;5;241m=\u001b[39mtol_R)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[100, 4, 4]' is invalid for input of size 900"
     ]
    }
   ],
   "source": [
    "# Verify anchors are valid SE(3)\n",
    "out = check_se3_flat(anchors_tensor, tol_R=1e-4, tol_last=1e-6)\n",
    "print(f\"Anchors SE(3) validity: {out['ok'].float().mean():.4f}\")\n",
    "print(f\"Max ortho err: {out['max_orth_err']:.6e}, Max det err: {out['max_det_err']:.6e}, Max last row err: {out['max_last_row_err']:.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf252d40-f854-4e15-a5a2-42589a31aae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Labels (Voronoi Partitioning) ---\n",
      "    Training Data (T): 4000\n",
      "    Anchors/Particles (N): 100\n",
      "    Done. Created DataLoader with 16 batches.\n",
      "Created training loader with 16 batches\n",
      "Label tensor shape: torch.Size([4000]), unique labels: 100\n"
     ]
    }
   ],
   "source": [
    "# Create label dataset using Voronoi partitioning\n",
    "X_train_np = X_train.numpy()\n",
    "Y_train_np = Y_train.numpy()\n",
    "\n",
    "train_loader, L_train = create_label_dataset(\n",
    "    X_train_np, \n",
    "    Y_train_np, \n",
    "    anchors, \n",
    "    batch_size=256, \n",
    "    metric='euclidean'\n",
    ")\n",
    "print(f\"Created training loader with {len(train_loader)} batches\")\n",
    "print(f\"Label tensor shape: {L_train.shape}, unique labels: {L_train.unique().numel()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44007e50-ec8a-41ae-8262-9fea03fcc642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created validation loader with 4 batches\n"
     ]
    }
   ],
   "source": [
    "# Create validation loader\n",
    "X_val_np = torch.tensor(loaded[\"X_val\"], dtype=torch.float32).numpy()\n",
    "Y_val_np = torch.tensor(loaded[\"Y_val\"], dtype=torch.float32).numpy()\n",
    "\n",
    "# For validation, we still need labels (closest anchors)\n",
    "from scipy.spatial.distance import cdist\n",
    "val_distances = cdist(Y_val_np, anchors, metric='euclidean')\n",
    "val_labels = torch.tensor(np.argmin(val_distances, axis=1), dtype=torch.long)\n",
    "\n",
    "val_ds = TensorDataset(\n",
    "    torch.tensor(X_val_np, dtype=torch.float32),\n",
    "    val_labels\n",
    ")\n",
    "val_loader = DataLoader(val_ds, batch_size=256, shuffle=False, drop_last=False)\n",
    "print(f\"Created validation loader with {len(val_loader)} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53d79489-6bf9-4542-9d66-e0f1d0b785f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created: input_dim=9, num_anchors=100\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "input_dim = X_train.shape[1]  # 9 for SO(3) input\n",
    "output_dim = Y_train.shape[1]  # 16 for SE(3) output\n",
    "\n",
    "model = ProbabilisticFeedForward(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=128,\n",
    "    num_layers=4,\n",
    "    num_anchors=num_anchors,\n",
    "    dropout=0.1\n",
    ")\n",
    "print(f\"Model created: input_dim={input_dim}, num_anchors={num_anchors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2406087e-acda-47bd-8b72-2b09ca675797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([4, 9]), Logits shape: torch.Size([4, 100])\n",
      "Probabilities shape: torch.Size([4, 100]), Sum per sample: tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Test forward pass\n",
    "x_test = X_train[:4]\n",
    "logits = model(x_test)\n",
    "print(f\"Input shape: {x_test.shape}, Logits shape: {logits.shape}\")\n",
    "probs = F.softmax(logits, dim=1)\n",
    "print(f\"Probabilities shape: {probs.shape}, Sum per sample: {probs.sum(dim=1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63f06656-3967-4003-a439-25f9f85e39b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom training function for probabilistic model\n",
    "def train_probabilistic_model(\n",
    "    model: nn.Module,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    anchors: torch.Tensor,\n",
    "    lr: float,\n",
    "    num_epochs: int,\n",
    "    device,\n",
    "    weight_decay: float = 1e-4,\n",
    "    grad_clip: float = 1.0,\n",
    "    scheduler_patience: int = 300,\n",
    "    scheduler_factor: float = 0.8,\n",
    "    early_stop: int = 30,\n",
    "    verbose: bool = True,\n",
    "):\n",
    "    import copy\n",
    "    model = model.to(device)\n",
    "    anchors = anchors.to(device)\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    sched = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        opt, mode=\"min\", patience=scheduler_patience, factor=scheduler_factor\n",
    "    )\n",
    "\n",
    "    train_losses, val_losses, lrs = [], [], []\n",
    "    best_val, best_epoch = float(\"inf\"), -1\n",
    "    best_state, patience = None, 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        tr = 0.0\n",
    "        n_tr = 0\n",
    "        for batch in train_loader:\n",
    "            x, labels = batch\n",
    "            x, labels = x.to(device), labels.to(device)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(x)\n",
    "            loss = probabilistic_transformer_loss(logits, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip and grad_clip > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            opt.step()\n",
    "\n",
    "            bs = x.shape[0]\n",
    "            tr += loss.item() * bs\n",
    "            n_tr += bs\n",
    "\n",
    "        tr /= n_tr\n",
    "        train_losses.append(tr)\n",
    "\n",
    "        # ---- val ----\n",
    "        model.eval()\n",
    "        va = 0.0\n",
    "        n_va = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x, labels = batch\n",
    "                x, labels = x.to(device), labels.to(device)\n",
    "                logits = model(x)\n",
    "                loss = probabilistic_transformer_loss(logits, labels)\n",
    "\n",
    "                bs = x.shape[0]\n",
    "                va += loss.item() * bs\n",
    "                n_va += bs\n",
    "\n",
    "        va /= n_va\n",
    "        val_losses.append(va)\n",
    "\n",
    "        # ---- scheduler ----\n",
    "        sched.step(va)\n",
    "        lrs.append(opt.param_groups[0][\"lr\"])\n",
    "\n",
    "        # ---- best model ----\n",
    "        if va < best_val:\n",
    "            best_val, best_epoch = va, epoch\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if verbose and ((epoch == 0) or ((epoch + 1) % 20 == 0)):\n",
    "            print(\n",
    "                f\"epoch {epoch+1:4d} | train {tr:.3e} | val {va:.3e} | lr {opt.param_groups[0]['lr']:.1e}\"\n",
    "            )\n",
    "\n",
    "        if early_stop and patience >= early_stop:\n",
    "            break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    logs = dict(\n",
    "        train_losses=train_losses,\n",
    "        val_losses=val_losses,\n",
    "        lrs=lrs,\n",
    "        best_val_loss=best_val,\n",
    "        best_epoch=best_epoch,\n",
    "    )\n",
    "    return model, logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb009aa1-935a-45aa-84ee-cd652bea0ba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model, logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_probabilistic_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43manchors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manchors_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# disable early stopping\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 18\u001b[0m, in \u001b[0;36mtrain_probabilistic_model\u001b[0;34m(model, train_loader, val_loader, anchors, lr, num_epochs, device, weight_decay, grad_clip, scheduler_patience, scheduler_factor, early_stop, verbose)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_probabilistic_model\u001b[39m(\n\u001b[1;32m      3\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m      4\u001b[0m     train_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m ):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     anchors \u001b[38;5;241m=\u001b[39m anchors\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m     opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/cuda/__init__.py:372\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    371\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    376\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "model, logs = train_probabilistic_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    anchors=anchors_tensor,\n",
    "    lr=1e-3,\n",
    "    num_epochs=1000,\n",
    "    device='cuda',\n",
    "    weight_decay=0,\n",
    "    early_stop=0,      # disable early stopping\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1b893a8-613e-4d03-841a-3cccd7bd6d7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test prediction on training data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 3\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m anchors_cuda \u001b[38;5;241m=\u001b[39m anchors_tensor\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m predict(model, X_test, anchors_cuda, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpectation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/jupyter_stack/lib/python3.10/site-packages/torch/cuda/__init__.py:372\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    371\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    376\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "# Test prediction on training data\n",
    "model.eval()\n",
    "X_test = X_train[:100].to('cuda')\n",
    "anchors_cuda = anchors_tensor.to('cuda')\n",
    "\n",
    "Y_pred = predict(model, X_test, anchors_cuda, method='expectation')\n",
    "print(f\"Prediction shape: {Y_pred.shape}\")\n",
    "print(f\"Expected shape: (100, 16)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75fd67e5-7226-4703-a582-ecaefada2995",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Check if predictions are valid SE(3)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Y_pred_cpu \u001b[38;5;241m=\u001b[39m \u001b[43mY_pred\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      3\u001b[0m out \u001b[38;5;241m=\u001b[39m check_se3_flat(Y_pred_cpu, tol_R\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, tol_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions SE(3) validity: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Check if predictions are valid SE(3)\n",
    "Y_pred_cpu = Y_pred.cpu()\n",
    "out = check_se3_flat(Y_pred_cpu, tol_R=1e-2, tol_last=1e-6)\n",
    "print(f\"Predictions SE(3) validity: {out['ok'].float().mean():.4f}\")\n",
    "print(f\"Max ortho err: {out['max_orth_err']:.6e}, Max det err: {out['max_det_err']:.6e}, Max last row err: {out['max_last_row_err']:.6e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
